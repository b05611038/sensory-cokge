{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfe91f7-782d-46cd-b5fc-56d2028d97c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from openTSNE import TSNE\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.font_manager import FontProperties\n",
    "from adjustText import adjust_text\n",
    "\n",
    "from src.utils import load_pickle_obj\n",
    "from src.relative_embedding import (AnchorDescriptors,\n",
    "                                    DescriptorColors,\n",
    "                                    construct_relative_embeddings)\n",
    "\n",
    "from src.graph import description_graph\n",
    "from src.models import (ALBERT_embeddings,\n",
    "                        BERT_embeddings,\n",
    "                        BART_embeddings,\n",
    "                        GPT2_embeddings,\n",
    "                        RoBERTa_embeddings,\n",
    "                        T5_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9235543-6c09-4fb2-a620-42a9dbcda597",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_folder(file_dict, folder):\n",
    "    for ftype in file_dict:\n",
    "        file_dict[ftype] = os.path.join(folder, file_dict[ftype])\n",
    "        \n",
    "    return file_dict\n",
    "\n",
    "def load_embeddings(file_dict):\n",
    "    embeddings = {}\n",
    "    for embedding_type in file_dict:\n",
    "        if os.path.isfile(file_dict[embedding_type]):\n",
    "            embeddings[embedding_type] = load_pickle_obj(file_dict[embedding_type])\n",
    "        else:\n",
    "            embeddings[embedding_type] = None\n",
    "            \n",
    "    return embeddings\n",
    "\n",
    "def construct_embeddings_for_LMs(descriptions, anchor_descriptions, model_type, finetuned_models):\n",
    "    func, has_encoder, has_decoder = None, True, True\n",
    "    if model_type == 'ALBERT':\n",
    "        func = ALBERT_embeddings\n",
    "        has_decoder = False\n",
    "    elif model_type == 'BART':\n",
    "        func = BART_embeddings\n",
    "    elif model_type == 'BERT':\n",
    "        func = BERT_embeddings\n",
    "        has_decoder = False\n",
    "    elif model_type == 'GPT2':\n",
    "        func = GPT2_embeddings\n",
    "        has_encoder = False\n",
    "    elif model_type == 'RoBERTa':\n",
    "        func = RoBERTa_embeddings\n",
    "        has_decoder = False\n",
    "    elif model_type == 'T5':\n",
    "        func = T5_embeddings\n",
    "        \n",
    "    embedding_dict = {}\n",
    "    for status in ['pretrained', 'finetuned']:\n",
    "        if status == 'pretrained':\n",
    "            embedding_dict[status] = func(descriptions)\n",
    "        elif status == 'finetuned':\n",
    "            embedding_dict[status] = func(descriptions,\n",
    "                                          finetuned_model = finetuned_models[model_type])\n",
    "\n",
    "        if has_encoder:\n",
    "            embedding_dict[status] = construct_relative_embeddings(model_type,\n",
    "                                                                   'encoder',\n",
    "                                                                   anchor_descriptions,\n",
    "                                                                   embedding_dict[status])\n",
    "        if has_decoder:\n",
    "            embedding_dict[status] = construct_relative_embeddings(model_type,\n",
    "                                                                   'decoder',\n",
    "                                                                   anchor_descriptions,\n",
    "                                                                   embedding_dict[status])\n",
    "\n",
    "    reduced_embedding_dict = {}\n",
    "    for status in embedding_dict:\n",
    "        iter_idx = 0\n",
    "        reduced_embedding_dict[status] = {}\n",
    "        for sample_idx in embedding_dict[status]:\n",
    "            if embedding_dict[status][sample_idx]['description'] in anchor_descriptions:\n",
    "                continue\n",
    "            else:\n",
    "                reduced_embedding_dict[status][iter_idx] = embedding_dict[status][sample_idx]\n",
    "                iter_idx += 1\n",
    "\n",
    "    return reduced_embedding_dict\n",
    "\n",
    "def plot_relative_embeddings(ID_embeddings,\n",
    "                             OOD_embeddings,\n",
    "                             target_embedding, \n",
    "                             colored_descriptions, \n",
    "                             colors, \n",
    "                             dimension_reduction = 'tsne',\n",
    "                             tsne_perplexity = 30., \n",
    "                             tsne_seed = 42,\n",
    "                             switched_text = None,\n",
    "                             filename = None):\n",
    "    \n",
    "    assert dimension_reduction in ['pca', 'tsne']\n",
    "    if switched_text is not None:\n",
    "        assert isinstance(switched_text, dict)\n",
    "        \n",
    "    if filename is not None:\n",
    "        assert isinstance(filename, str)\n",
    "    \n",
    "    colors = copy.deepcopy(colors)\n",
    "    for color in colors:\n",
    "        colors[color] =  tuple([value / 255 for value in colors[color]])\n",
    "    \n",
    "    all_descritpions = []\n",
    "    for color in colored_descriptions:\n",
    "        all_descritpions += colored_descriptions[color]\n",
    "        \n",
    "    in_embeddings, ood_embeddings = {}, {}\n",
    "    for des_name in all_descritpions:\n",
    "        detect = False\n",
    "        for idx in ID_embeddings:\n",
    "            if des_name == ID_embeddings[idx]['description']:\n",
    "                in_embeddings[des_name] = ID_embeddings[idx][target_embedding]\n",
    "                detect = True\n",
    "                break\n",
    "\n",
    "        if not detect:\n",
    "            for idx in OOD_embeddings:\n",
    "                if des_name == OOD_embeddings[idx]['description']:\n",
    "                    ood_embeddings[des_name] = OOD_embeddings[idx][target_embedding]\n",
    "                    detect = True\n",
    "                    break\n",
    "\n",
    "        if not detect:\n",
    "            print('Descriptor: {0} cannot find its embeddings.'.format(des_name))\n",
    "                                \n",
    "    assert (len(in_embeddings) + len(ood_embeddings)) == len(all_descritpions)\n",
    "    \n",
    "    data_matrix, in_groups = [], []\n",
    "    for des_name in in_embeddings:\n",
    "        data_matrix.append(in_embeddings[des_name])\n",
    "        for color in colored_descriptions:\n",
    "            if des_name in colored_descriptions[color]:\n",
    "                detect_color = color\n",
    "                break\n",
    "            \n",
    "        in_groups.append(detect_color)\n",
    "        \n",
    "    data_matrix = torch.stack(data_matrix).numpy()\n",
    "    \n",
    "    ood_data_matrix, ood_groups = [], []\n",
    "    for des_name in ood_embeddings:\n",
    "        ood_data_matrix.append(ood_embeddings[des_name])\n",
    "        for color in colored_descriptions:\n",
    "            if des_name in colored_descriptions[color]:\n",
    "                detect_color = color\n",
    "\n",
    "        ood_groups.append(detect_color)\n",
    "\n",
    "    ood_data_matrix = torch.stack(ood_data_matrix).numpy()\n",
    "    \n",
    "    if dimension_reduction == 'pca':\n",
    "        pca = PCA(n_components = 2)\n",
    "        in_components = pca.fit_transform(data_matrix)\n",
    "        ood_components = pca.transform(ood_data_matrix)\n",
    "    elif dimension_reduction == 'tsne':    \n",
    "        tsne = TSNE(n_components = 2,\n",
    "                    initialization = 'pca',\n",
    "                    perplexity = tsne_perplexity,\n",
    "                    random_state = tsne_seed)\n",
    "    \n",
    "        tsne_embeddings = tsne.fit(data_matrix)\n",
    "        in_components = np.array(tsne_embeddings)        \n",
    "        ood_components = tsne_embeddings.transform(ood_data_matrix)\n",
    "        ood_components = np.array(ood_components)\n",
    "    \n",
    "    in_df = pd.DataFrame(data = in_components, columns = ['Dim1', 'Dim2'])\n",
    "    in_df['Group'] = in_groups\n",
    "    ood_df = pd.DataFrame(data = ood_components, columns = ['Dim1', 'Dim2'])\n",
    "    ood_df['Group'] = ood_groups\n",
    "\n",
    "    fig, ax = plt.subplots(figsize = (10, 10))\n",
    "    unique_in_groups = in_df['Group'].unique()  \n",
    "    for group in unique_in_groups:\n",
    "        indices = in_df['Group'] == group\n",
    "        ax.scatter(in_df.loc[indices, 'Dim1'],\n",
    "                   in_df.loc[indices, 'Dim2'],\n",
    "                   c = [colors[group]],\n",
    "                   edgecolor = None,\n",
    "                   alpha = 0.25,\n",
    "                   s = 100)\n",
    "\n",
    "    unique_ood_groups = ood_df['Group'].unique()\n",
    "    for group in unique_ood_groups:\n",
    "        indices = ood_df['Group'] == group\n",
    "        ax.scatter(ood_df.loc[indices, 'Dim1'],\n",
    "                   ood_df.loc[indices, 'Dim2'],\n",
    "                   c = [colors[group]],\n",
    "                   edgecolor = 'black',\n",
    "                   alpha = 1.,\n",
    "                   s = 100)\n",
    "\n",
    "    iter_idx = 0\n",
    "    times = FontProperties(family = \"Times New Roman\", size = 32)\n",
    "    annotations = []\n",
    "    for descriptor in ood_embeddings:\n",
    "        if switched_text is not None:\n",
    "            if descriptor in switched_text:\n",
    "                descriptor = switched_text[descriptor]\n",
    "            \n",
    "        annotations.append(ax.annotate(descriptor, (ood_components[iter_idx, 0], ood_components[iter_idx, 1]),\n",
    "                    fontproperties = times, fontweight = 'bold', ha = 'left', va = 'bottom'))\n",
    "\n",
    "        iter_idx += 1\n",
    "\n",
    "    adjust_text(annotations, ax = ax)\n",
    "    \n",
    "    if dimension_reduction == 'pca':\n",
    "        plt.xlabel('PCA Dim 1')\n",
    "        plt.ylabel('PCA Dim 2')\n",
    "        plt.title('PCA of LLM embeddings')\n",
    "    elif dimension_reduction == 'tsne':\n",
    "        plt.xlabel('t-SNE Dim 1')\n",
    "        plt.ylabel('t-SNE Dim 2')\n",
    "        plt.title('t-SNE of LLM embeddings')\n",
    "\n",
    "    if filename is not None:\n",
    "        if not filename.endswith('.png'):\n",
    "            filename += '.png'\n",
    "\n",
    "        plt.savefig(filename, \n",
    "                    dpi = 300, \n",
    "                    bbox_inches = 'tight')\n",
    "        print('Save as file: {0} successfully.'.format(filename))\n",
    "    else:\n",
    "        plt.show()\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5fa9e1-2973-441d-a3e2-56cfe59e95ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = './outputs'\n",
    "bert_files = {'pretrained': 'pretrained-BERT_embeddings.pkl',\n",
    "              'finetuned': 'finetuned-BERT-N20kE3_embeddings.pkl'}\n",
    "roberta_files = {'pretrained': 'pretrained-RoBERTa_embeddings.pkl',\n",
    "                 'finetuned': 'finetuned-RoBERTa-N100kE1_embeddings.pkl'}\n",
    "\n",
    "model_folder = 'finetuned_models'\n",
    "finetuned_models = {'BERT': 'finetuned-bert-base-uncased-N20kE3',\n",
    "                    'RoBERTa': 'finetuned-roberta-base-N100kE1'}\n",
    "\n",
    "finetuned_models = concat_folder(finetuned_models, model_folder)\n",
    "\n",
    "bert_files = concat_folder(bert_files, folder_name)\n",
    "roberta_files = concat_folder(roberta_files, folder_name)\n",
    "\n",
    "ID_bert_embeddings = load_embeddings(bert_files)\n",
    "ID_roberta_embeddings = load_embeddings(roberta_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff416ca-a796-45a4-9647-aee839f7ce71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The warning is caused by the lack of saving parameter of the linear predictor\n",
    "# Becuase embeddings are extracted at the output of the main computational module,\n",
    "# it do not affect the result of Sensory-CoKGE.\n",
    "anchor_descriptions = copy.deepcopy(AnchorDescriptors)\n",
    "OOD_descriptions = {'OOD_fruity': ['waxberry', 'banana', 'dragon fruit', 'mango'],\n",
    "                    'OOD_sour/fermented': ['tartaric acidity', 'phosphoric acidity', 'beer', 'Bourbon wine']}\n",
    "\n",
    "switched_text = {'waxberry': 'F1',\n",
    "                 'banana': 'F2',\n",
    "                 'dragon fruit': 'F3',\n",
    "                 'mango': 'F4',\n",
    "                 'tartaric acidity': 'S1',\n",
    "                 'phosphoric acidity': 'S2',\n",
    "                 'beer': 'S3',\n",
    "                 'Bourbon wine': 'S4'}\n",
    "\n",
    "descriptions = copy.deepcopy(anchor_descriptions)\n",
    "for OOD_group in OOD_descriptions:\n",
    "    descriptions += OOD_descriptions[OOD_group]\n",
    "\n",
    "OOD_bert_embeddings = construct_embeddings_for_LMs(descriptions, anchor_descriptions, 'BERT', finetuned_models)\n",
    "OOD_roberta_embeddings = construct_embeddings_for_LMs(descriptions, anchor_descriptions, 'RoBERTa', finetuned_models)\n",
    "\n",
    "colored_descriptions = {}\n",
    "description_colors = copy.deepcopy(DescriptorColors)\n",
    "\n",
    "graph = description_graph()\n",
    "for descritpion in graph.descriptions:\n",
    "    for color in description_colors:\n",
    "        if graph.distance_between_descriptions(descritpion, color) < 10.:\n",
    "            if color not in colored_descriptions.keys():\n",
    "                colored_descriptions[color] = [descritpion]\n",
    "            else:\n",
    "                colored_descriptions[color].append(descritpion)  \n",
    "                \n",
    "for color in colored_descriptions:\n",
    "    colored_descriptions[color] = list(set(colored_descriptions[color]))\n",
    "\n",
    "for OOD_group in OOD_descriptions:\n",
    "    for color_group in description_colors:\n",
    "        if color_group in OOD_group:\n",
    "            colored_descriptions[OOD_group] = OOD_descriptions[OOD_group]\n",
    "            description_colors[OOD_group] = description_colors[color_group]\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f627f64a-cf0b-4aad-8df7-31105b2724f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f157ac6-4479-4ee2-8891-9a5808f5367d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following code generates a figure from the submitted manuscript\n",
    "# Removed due to journal review policy\n",
    "# pretained BERT\n",
    "plot_relative_embeddings(ID_bert_embeddings['pretrained'],\n",
    "                         OOD_bert_embeddings['pretrained'],\n",
    "                         'relative_encoder_embedding',\n",
    "                         colored_descriptions,\n",
    "                         description_colors,\n",
    "                         switched_text = switched_text,\n",
    "                         filename = 'OOD_Pretrained_BERT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e86620b-ee19-4711-bfdc-c520e6dfcbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following code generates a figure from the submitted manuscript\n",
    "# Removed due to journal review policy\n",
    "# finetuned BERT\n",
    "plot_relative_embeddings(ID_bert_embeddings['finetuned'],\n",
    "                         OOD_bert_embeddings['finetuned'],\n",
    "                         'relative_encoder_embedding',\n",
    "                         colored_descriptions,\n",
    "                         description_colors,\n",
    "                         switched_text = switched_text,\n",
    "                         filename = 'OOD_Finetuned_BERT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd271233-b734-404d-bd6b-8bfb58d497cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following code generates a figure from the submitted manuscript\n",
    "# Removed due to journal review policy\n",
    "# pretained RoBERTa\n",
    "plot_relative_embeddings(ID_roberta_embeddings['pretrained'],\n",
    "                         OOD_roberta_embeddings['pretrained'],\n",
    "                         'relative_encoder_embedding',\n",
    "                         colored_descriptions,\n",
    "                         description_colors,\n",
    "                         switched_text = switched_text,\n",
    "                         filename = 'OOD_Pretrained_RoBERTa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754c97e9-ca08-440c-86fe-7cd81773abeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following code generates a figure from the submitted manuscript\n",
    "# Removed due to journal review policy\n",
    "# finetuned RoBERTa\n",
    "plot_relative_embeddings(ID_roberta_embeddings['finetuned'],\n",
    "                         OOD_roberta_embeddings['finetuned'],\n",
    "                         'relative_encoder_embedding',\n",
    "                         colored_descriptions,\n",
    "                         description_colors,\n",
    "                         switched_text = switched_text,\n",
    "                         filename = 'OOD_Finetuned_RoBERTa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ad5113-310c-406b-a416-9f04d2624d41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
